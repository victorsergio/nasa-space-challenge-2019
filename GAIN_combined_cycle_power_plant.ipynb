{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAIN_combined_cycle_power_plant.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"mgmHQCk8AvuT","colab_type":"code","outputId":"4d471333-4153-4b0e-9f19-fccfe940ca33","executionInfo":{"status":"ok","timestamp":1571633143943,"user_tz":360,"elapsed":954,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# replace this path with your data folder location\n","data_path = \"/content/drive/My Drive/GAIN/nasa space challenge 2019/data/\"\n","\n","# replace this path with your root path\n","root_path = \"/content/drive/My Drive/GAIN/nasa space challenge 2019/\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-KOzO8f28ubA","colab_type":"text"},"source":["## UCI - Combined Cycle Power Plant Data Set\n","\n","### Abstract: \n","The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the plant was set to work with full load.\n","\n","### Data Set Information:\n","\n","The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (PE) of the plant.\n","\n","https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant"]},{"cell_type":"code","metadata":{"id":"6OwC_w1e09aj","colab_type":"code","outputId":"c57a8f6c-6fc3-4609-bb9b-0ba88134b27e","executionInfo":{"status":"ok","timestamp":1571633144219,"user_tz":360,"elapsed":1154,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["import pandas as pd\n","# Data generation\n","original_dataset = pd.read_csv(data_path+\"power_plant.csv\", sep=',')\n","original_dataset.head(5)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AT</th>\n","      <th>V</th>\n","      <th>AP</th>\n","      <th>RH</th>\n","      <th>PE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8.34</td>\n","      <td>40.77</td>\n","      <td>1010.84</td>\n","      <td>90.01</td>\n","      <td>480.48</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>23.64</td>\n","      <td>58.49</td>\n","      <td>1011.40</td>\n","      <td>74.20</td>\n","      <td>445.75</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>29.74</td>\n","      <td>56.90</td>\n","      <td>1007.15</td>\n","      <td>41.91</td>\n","      <td>438.76</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>19.07</td>\n","      <td>49.69</td>\n","      <td>1007.22</td>\n","      <td>76.79</td>\n","      <td>453.09</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11.80</td>\n","      <td>40.66</td>\n","      <td>1017.13</td>\n","      <td>97.20</td>\n","      <td>464.43</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      AT      V       AP     RH      PE\n","0   8.34  40.77  1010.84  90.01  480.48\n","1  23.64  58.49  1011.40  74.20  445.75\n","2  29.74  56.90  1007.15  41.91  438.76\n","3  19.07  49.69  1007.22  76.79  453.09\n","4  11.80  40.66  1017.13  97.20  464.43"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"J-tjcjBqPo92","colab_type":"code","colab":{}},"source":["# Modification to use another normalization techniques\n","# Normalization (0 to 1)  \n","from sklearn.preprocessing import MinMaxScaler, RobustScaler   \n","scaler = MinMaxScaler()\n","original_dataset[original_dataset.columns] = scaler.fit_transform(original_dataset[original_dataset.columns])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-PRKybF8RFXg","colab_type":"code","outputId":"463cfb64-d1e7-4a7c-9695-86db86f4d627","executionInfo":{"status":"ok","timestamp":1571633144501,"user_tz":360,"elapsed":1234,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["original_dataset.describe()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AT</th>\n","      <th>V</th>\n","      <th>AP</th>\n","      <th>RH</th>\n","      <th>PE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>9568.000000</td>\n","      <td>9568.000000</td>\n","      <td>9568.000000</td>\n","      <td>9568.000000</td>\n","      <td>9568.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.505417</td>\n","      <td>0.515050</td>\n","      <td>0.504060</td>\n","      <td>0.640067</td>\n","      <td>0.451722</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.211118</td>\n","      <td>0.226119</td>\n","      <td>0.146963</td>\n","      <td>0.195714</td>\n","      <td>0.226053</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.331445</td>\n","      <td>0.291459</td>\n","      <td>0.401138</td>\n","      <td>0.506267</td>\n","      <td>0.258146</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.525071</td>\n","      <td>0.475445</td>\n","      <td>0.496164</td>\n","      <td>0.662399</td>\n","      <td>0.414437</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.677337</td>\n","      <td>0.732740</td>\n","      <td>0.603069</td>\n","      <td>0.794504</td>\n","      <td>0.638013</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                AT            V           AP           RH           PE\n","count  9568.000000  9568.000000  9568.000000  9568.000000  9568.000000\n","mean      0.505417     0.515050     0.504060     0.640067     0.451722\n","std       0.211118     0.226119     0.146963     0.195714     0.226053\n","min       0.000000     0.000000     0.000000     0.000000     0.000000\n","25%       0.331445     0.291459     0.401138     0.506267     0.258146\n","50%       0.525071     0.475445     0.496164     0.662399     0.414437\n","75%       0.677337     0.732740     0.603069     0.794504     0.638013\n","max       1.000000     1.000000     1.000000     1.000000     1.000000"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"qdy9rcUe1MqP","colab_type":"code","colab":{}},"source":["# split original dataset (train,test)\n","# test_set wont have missing values for realistic algorithm comparison\n","\n","from sklearn.model_selection import train_test_split\n","\n","# we will use full_set to compare MSE between [original dataset vs GAIN generated dataset]\n","full_set, test_set = train_test_split(original_dataset, test_size=0.50, random_state=2)\n","\n","# we will take 80% of dataset to compare MSE between [GAIN generated dataset (full_set) vs partial_set (Full set at 20% missing)] \n","partial_set, _ = train_test_split(full_set,test_size = 0.2, random_state=1)\n","\n","\n","Data = full_set.to_numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"je24a5Sg9oUF","colab_type":"text"},"source":["## Generative Adversarial Imputation Networks (GAIN)\n","\n","Written by Jinsung Yoon\n","Date: Jan 29th 2019\n","Generative Adversarial Imputation Networks (GAIN) Implementation on Spam \n","Dataset Reference: J. Yoon, J. Jordon, M. van der Schaar, \"GAIN: Missing Data Imputation using Generative Adversarial Nets,\" ICML, 2018."]},{"cell_type":"code","metadata":{"id":"ch4aV0Ydtu49","colab_type":"code","outputId":"041027b1-f803-46f9-c034-1b04f198d4c3","executionInfo":{"status":"ok","timestamp":1571633158395,"user_tz":360,"elapsed":15101,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["'''\n","Written by Jinsung Yoon\n","Date: Jan 29th 2019\n","Generative Adversarial Imputation Networks (GAIN) Implementation on Spam Dataset\n","Reference: J. Yoon, J. Jordon, M. van der Schaar, \"GAIN: Missing Data Imputation using Generative Adversarial Nets,\" ICML, 2018.\n","Paper Link: http://medianetlab.ee.ucla.edu/papers/ICML_GAIN.pdf\n","Appendix Link: http://medianetlab.ee.ucla.edu/papers/ICML_GAIN_Supp.pdf\n","Contact: jsyoon0823@g.ucla.edu\n","'''\n","\n","#%% Packages\n","import tensorflow as tf\n","import numpy as np\n","from tqdm import tqdm\n","\n","#%% System Parameters\n","# 1. Mini batch size\n","mb_size = 128\n","# 2. Missing rate\n","p_miss = 0.2\n","# 3. Hint rate\n","p_hint = 0.9\n","# 4. Loss Hyperparameters\n","alpha = 10\n","# 5. Train Rate\n","train_rate = 0.8\n","\n","#%% Data\n","\n","# Data generation\n","#Data = np.loadtxt(data_path+\"power_plant.csv\", delimiter=\",\",skiprows=1)\n","\n","# Parameters\n","No = len(Data)\n","Dim = len(Data[0,:])\n","\n","# Hidden state dimensions\n","H_Dim1 = Dim\n","H_Dim2 = Dim\n","\n","# Normalization (0 to 1)\n","#Min_Val = np.zeros(Dim)\n","#Max_Val = np.zeros(Dim)\n","\n","#for i in range(Dim):\n","#    Min_Val[i] = np.min(Data[:,i])\n","#    Data[:,i] = Data[:,i] - np.min(Data[:,i])\n","#    Max_Val[i] = np.max(Data[:,i])\n","#    Data[:,i] = Data[:,i] / (np.max(Data[:,i]) + 1e-6)   \n"," \n","\n","#%% Missing introducing\n","p_miss_vec = p_miss * np.ones((Dim,1)) \n","   \n","Missing = np.zeros((No,Dim))\n","\n","for i in range(Dim):\n","    A = np.random.uniform(0., 1., size = [len(Data),])\n","    B = A > p_miss_vec[i]\n","    Missing[:,i] = 1.*B\n","\n","    \n","#%% Train Test Division    \n","   \n","idx = np.random.permutation(No)\n","\n","Train_No = int(No * train_rate)\n","Test_No = No - Train_No\n","    \n","# Train / Test Features\n","trainX = Data[idx[:Train_No],:]\n","testX = Data[idx[Train_No:],:]\n","\n","# Train / Test Missing Indicators\n","trainM = Missing[idx[:Train_No],:]\n","testM = Missing[idx[Train_No:],:]\n","\n","#%% Necessary Functions\n","\n","# 1. Xavier Initialization Definition\n","def xavier_init(size):\n","    in_dim = size[0]\n","    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n","    return tf.random_normal(shape = size, stddev = xavier_stddev)\n","    \n","# Hint Vector Generation\n","def sample_M(m, n, p):\n","    A = np.random.uniform(0., 1., size = [m, n])\n","    B = A > p\n","    C = 1.*B\n","    return C\n","   \n","'''\n","GAIN Consists of 3 Components\n","- Generator\n","- Discriminator\n","- Hint Mechanism\n","'''   \n","   \n","#%% GAIN Architecture   \n","   \n","#%% 1. Input Placeholders\n","# 1.1. Data Vector\n","X = tf.placeholder(tf.float32, shape = [None, Dim])\n","# 1.2. Mask Vector \n","M = tf.placeholder(tf.float32, shape = [None, Dim])\n","# 1.3. Hint vector\n","H = tf.placeholder(tf.float32, shape = [None, Dim])\n","# 1.4. X with missing values\n","New_X = tf.placeholder(tf.float32, shape = [None, Dim])\n","\n","#%% 2. Discriminator\n","D_W1 = tf.Variable(xavier_init([Dim*2, H_Dim1]))     # Data + Hint as inputs\n","D_b1 = tf.Variable(tf.zeros(shape = [H_Dim1]))\n","\n","D_W2 = tf.Variable(xavier_init([H_Dim1, H_Dim2]))\n","D_b2 = tf.Variable(tf.zeros(shape = [H_Dim2]))\n","\n","D_W3 = tf.Variable(xavier_init([H_Dim2, Dim]))\n","D_b3 = tf.Variable(tf.zeros(shape = [Dim]))       # Output is multi-variate\n","\n","theta_D = [D_W1, D_W2, D_W3, D_b1, D_b2, D_b3]\n","\n","#%% 3. Generator\n","G_W1 = tf.Variable(xavier_init([Dim*2, H_Dim1]))     # Data + Mask as inputs (Random Noises are in Missing Components)\n","G_b1 = tf.Variable(tf.zeros(shape = [H_Dim1]))\n","\n","G_W2 = tf.Variable(xavier_init([H_Dim1, H_Dim2]))\n","G_b2 = tf.Variable(tf.zeros(shape = [H_Dim2]))\n","\n","G_W3 = tf.Variable(xavier_init([H_Dim2, Dim]))\n","G_b3 = tf.Variable(tf.zeros(shape = [Dim]))\n","\n","theta_G = [G_W1, G_W2, G_W3, G_b1, G_b2, G_b3]\n","\n","#%% GAIN Function\n","\n","#%% 1. Generator\n","def generator(new_x,m):\n","    inputs = tf.concat(axis = 1, values = [new_x,m])  # Mask + Data Concatenate\n","    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n","    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)   \n","    G_prob = tf.nn.sigmoid(tf.matmul(G_h2, G_W3) + G_b3) # [0,1] normalized Output\n","    \n","    return G_prob\n","    \n","#%% 2. Discriminator\n","def discriminator(new_x, h):\n","    inputs = tf.concat(axis = 1, values = [new_x,h])  # Hint + Data Concatenate\n","    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)  \n","    D_h2 = tf.nn.relu(tf.matmul(D_h1, D_W2) + D_b2)\n","    D_logit = tf.matmul(D_h2, D_W3) + D_b3\n","    D_prob = tf.nn.sigmoid(D_logit)  # [0,1] Probability Output\n","    \n","    return D_prob\n","\n","#%% 3. Other functions\n","# Random sample generator for Z\n","def sample_Z(m, n):\n","    return np.random.uniform(0., 0.01, size = [m, n])        \n","\n","# Mini-batch generation\n","def sample_idx(m, n):\n","    A = np.random.permutation(m)\n","    idx = A[:n]\n","    return idx\n","\n","#%% Structure\n","# Generator\n","G_sample = generator(New_X,M)\n","\n","# Combine with original data\n","Hat_New_X = New_X * M + G_sample * (1-M)\n","\n","# Discriminator\n","D_prob = discriminator(Hat_New_X, H)\n","\n","#%% Loss\n","D_loss1 = -tf.reduce_mean(M * tf.log(D_prob + 1e-8) + (1-M) * tf.log(1. - D_prob + 1e-8)) \n","G_loss1 = -tf.reduce_mean((1-M) * tf.log(D_prob + 1e-8))\n","MSE_train_loss = tf.reduce_mean((M * New_X - M * G_sample)**2) / tf.reduce_mean(M)\n","\n","D_loss = D_loss1\n","G_loss = G_loss1 + alpha * MSE_train_loss \n","\n","#%% MSE Performance metric\n","MSE_test_loss = tf.reduce_mean(((1-M) * X - (1-M)*G_sample)**2) / tf.reduce_mean(1-M)\n","\n","#%% Solver\n","D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n","G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n","\n","# Sessions\n","sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","#%% Iterations\n","\n","#%% Start Iterations\n","for it in tqdm(range(5000)):    \n","    \n","    #%% Inputs\n","    mb_idx = sample_idx(Train_No, mb_size)\n","    X_mb = trainX[mb_idx,:]  \n","    \n","    Z_mb = sample_Z(mb_size, Dim) \n","    M_mb = trainM[mb_idx,:]  \n","    H_mb1 = sample_M(mb_size, Dim, 1-p_hint)\n","    H_mb = M_mb * H_mb1\n","    \n","    New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n","    \n","    _, D_loss_curr = sess.run([D_solver, D_loss1], feed_dict = {M: M_mb, New_X: New_X_mb, H: H_mb})\n","    _, G_loss_curr, MSE_train_loss_curr, MSE_test_loss_curr = sess.run([G_solver, G_loss1, MSE_train_loss, MSE_test_loss],\n","                                                                       feed_dict = {X: X_mb, M: M_mb, New_X: New_X_mb, H: H_mb})\n","            \n","        \n","    #%% Intermediate Losses\n","    if it % 100 == 0:\n","        print('Iter: {}'.format(it))\n","        print('Train_loss: {:.4}'.format(np.sqrt(MSE_train_loss_curr)))\n","        print('Test_loss: {:.4}'.format(np.sqrt(MSE_test_loss_curr)))\n","        print()\n","\n","#%% Final Loss\n","    \n","Z_mb = sample_Z(Test_No, Dim) \n","M_mb = testM\n","X_mb = testX\n","\n","        \n","New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n","    \n","MSE_final, Sample = sess.run([MSE_test_loss, G_sample], feed_dict = {X: testX, M: testM, New_X: New_X_mb})\n","        \n","print('\\nFinal Test RMSE: ' + str(np.sqrt(MSE_final)))\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["  1%|          | 44/5000 [00:00<07:28, 11.05it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 0\n","Train_loss: 0.2076\n","Test_loss: 0.2293\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  4%|▎         | 184/5000 [00:00<02:36, 30.79it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 100\n","Train_loss: 0.2093\n","Test_loss: 0.2264\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  6%|▌         | 276/5000 [00:00<01:20, 58.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 200\n","Train_loss: 0.1768\n","Test_loss: 0.2043\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  7%|▋         | 363/5000 [00:00<00:44, 104.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 300\n","Train_loss: 0.1648\n","Test_loss: 0.2067\n","\n"],"name":"stdout"},{"output_type":"stream","text":["  9%|▉         | 454/5000 [00:01<00:26, 172.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 400\n","Train_loss: 0.1418\n","Test_loss: 0.1707\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|█▏        | 591/5000 [00:01<00:15, 290.87it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 500\n","Train_loss: 0.1255\n","Test_loss: 0.1736\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 14%|█▎        | 684/5000 [00:01<00:12, 356.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 600\n","Train_loss: 0.1177\n","Test_loss: 0.1667\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|█▌        | 779/5000 [00:01<00:10, 406.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 700\n","Train_loss: 0.1254\n","Test_loss: 0.1627\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 18%|█▊        | 875/5000 [00:02<00:09, 436.21it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 800\n","Train_loss: 0.1118\n","Test_loss: 0.125\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 19%|█▉        | 969/5000 [00:02<00:09, 441.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 900\n","Train_loss: 0.1061\n","Test_loss: 0.1623\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 21%|██        | 1062/5000 [00:02<00:08, 447.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1000\n","Train_loss: 0.1078\n","Test_loss: 0.165\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 23%|██▎       | 1154/5000 [00:02<00:08, 447.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1100\n","Train_loss: 0.1166\n","Test_loss: 0.1397\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 26%|██▌       | 1292/5000 [00:02<00:08, 446.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1200\n","Train_loss: 0.1146\n","Test_loss: 0.1285\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 28%|██▊       | 1385/5000 [00:03<00:08, 439.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1300\n","Train_loss: 0.1109\n","Test_loss: 0.161\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 30%|██▉       | 1475/5000 [00:03<00:08, 437.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1400\n","Train_loss: 0.1031\n","Test_loss: 0.1245\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 31%|███▏      | 1567/5000 [00:03<00:07, 446.87it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1500\n","Train_loss: 0.1048\n","Test_loss: 0.1359\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 1660/5000 [00:03<00:07, 455.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1600\n","Train_loss: 0.09602\n","Test_loss: 0.1552\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 35%|███▌      | 1754/5000 [00:04<00:07, 455.02it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1700\n","Train_loss: 0.105\n","Test_loss: 0.1715\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 38%|███▊      | 1891/5000 [00:04<00:06, 449.90it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1800\n","Train_loss: 0.1017\n","Test_loss: 0.1684\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 40%|███▉      | 1982/5000 [00:04<00:06, 440.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 1900\n","Train_loss: 0.09816\n","Test_loss: 0.1692\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 41%|████▏     | 2073/5000 [00:04<00:06, 445.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2000\n","Train_loss: 0.09919\n","Test_loss: 0.1805\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 43%|████▎     | 2165/5000 [00:04<00:06, 452.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2100\n","Train_loss: 0.09972\n","Test_loss: 0.1749\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|████▌     | 2256/5000 [00:05<00:06, 437.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2200\n","Train_loss: 0.09376\n","Test_loss: 0.1662\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 48%|████▊     | 2392/5000 [00:05<00:05, 444.91it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2300\n","Train_loss: 0.09462\n","Test_loss: 0.1615\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 50%|████▉     | 2483/5000 [00:05<00:05, 448.81it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2400\n","Train_loss: 0.09277\n","Test_loss: 0.1855\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 51%|█████▏    | 2573/5000 [00:05<00:05, 445.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2500\n","Train_loss: 0.09238\n","Test_loss: 0.17\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 53%|█████▎    | 2663/5000 [00:06<00:05, 444.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2600\n","Train_loss: 0.08231\n","Test_loss: 0.1803\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 55%|█████▌    | 2755/5000 [00:06<00:05, 447.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2700\n","Train_loss: 0.08613\n","Test_loss: 0.1261\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 58%|█████▊    | 2894/5000 [00:06<00:04, 452.55it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2800\n","Train_loss: 0.09097\n","Test_loss: 0.1598\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 60%|█████▉    | 2987/5000 [00:06<00:04, 456.75it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 2900\n","Train_loss: 0.08681\n","Test_loss: 0.1542\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 62%|██████▏   | 3081/5000 [00:07<00:04, 451.95it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3000\n","Train_loss: 0.0771\n","Test_loss: 0.1422\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 63%|██████▎   | 3172/5000 [00:07<00:04, 441.75it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3100\n","Train_loss: 0.0864\n","Test_loss: 0.1393\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 65%|██████▌   | 3262/5000 [00:07<00:03, 440.26it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3200\n","Train_loss: 0.07418\n","Test_loss: 0.1349\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 3353/5000 [00:07<00:03, 429.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3300\n","Train_loss: 0.07929\n","Test_loss: 0.1161\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 70%|██████▉   | 3490/5000 [00:07<00:03, 442.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3400\n","Train_loss: 0.06492\n","Test_loss: 0.1377\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 72%|███████▏  | 3581/5000 [00:08<00:03, 444.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3500\n","Train_loss: 0.07623\n","Test_loss: 0.1409\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 74%|███████▎  | 3675/5000 [00:08<00:02, 453.26it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3600\n","Train_loss: 0.07339\n","Test_loss: 0.1402\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 75%|███████▌  | 3768/5000 [00:08<00:02, 452.20it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3700\n","Train_loss: 0.07665\n","Test_loss: 0.1212\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 77%|███████▋  | 3859/5000 [00:08<00:02, 444.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3800\n","Train_loss: 0.07184\n","Test_loss: 0.1269\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 79%|███████▉  | 3949/5000 [00:08<00:02, 438.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 3900\n","Train_loss: 0.07198\n","Test_loss: 0.1243\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 82%|████████▏ | 4080/5000 [00:09<00:02, 423.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4000\n","Train_loss: 0.07242\n","Test_loss: 0.1488\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 83%|████████▎ | 4167/5000 [00:09<00:01, 420.48it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4100\n","Train_loss: 0.06656\n","Test_loss: 0.1323\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 85%|████████▌ | 4258/5000 [00:09<00:01, 434.66it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4200\n","Train_loss: 0.06668\n","Test_loss: 0.1295\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 87%|████████▋ | 4346/5000 [00:09<00:01, 434.21it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4300\n","Train_loss: 0.06767\n","Test_loss: 0.1268\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 90%|████████▉ | 4481/5000 [00:10<00:01, 438.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4400\n","Train_loss: 0.06947\n","Test_loss: 0.133\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 91%|█████████▏| 4569/5000 [00:10<00:00, 437.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4500\n","Train_loss: 0.07302\n","Test_loss: 0.1392\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 93%|█████████▎| 4658/5000 [00:10<00:00, 433.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4600\n","Train_loss: 0.06546\n","Test_loss: 0.1191\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 95%|█████████▍| 4749/5000 [00:10<00:00, 441.88it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4700\n","Train_loss: 0.06674\n","Test_loss: 0.1474\n","\n"],"name":"stdout"},{"output_type":"stream","text":[" 98%|█████████▊| 4889/5000 [00:11<00:00, 452.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4800\n","Train_loss: 0.06785\n","Test_loss: 0.1245\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|█████████▉| 4982/5000 [00:11<00:00, 443.91it/s]"],"name":"stderr"},{"output_type":"stream","text":["Iter: 4900\n","Train_loss: 0.06521\n","Test_loss: 0.1375\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 5000/5000 [00:11<00:00, 439.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Final Test RMSE: 0.13771257\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"deuhlvIj-WfN","colab_type":"text"},"source":["## Impute missing data for CCPower Plant dataset\n","Using GAIN technique, impute missing data on CCPower Plant dataset "]},{"cell_type":"code","metadata":{"id":"oe6dfgaauhcw","colab_type":"code","colab":{}},"source":["# Generate a dataframe with GAIN generated values\n","    \n","Z_mb = sample_Z(len(Data), Dim) \n","M_mb = Missing\n","X_mb = Data\n","        \n","New_X_mb = M_mb * X_mb + (1-M_mb) * Z_mb  # Missing Data Introduce\n","    \n","MSE_final, result = sess.run([MSE_test_loss, G_sample], feed_dict = {X: Data, M: Missing, New_X: New_X_mb})\n","        \n","# result is the imputed dataset\n","result = M_mb * X_mb + (1-M_mb) * result"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oRwBEQuAAXGd","colab_type":"text"},"source":["## Visual comparison of the resulting imputed data\n","The missing data matrix represent the valid and missing data cells"]},{"cell_type":"code","metadata":{"id":"kt7JsmMQ8a1N","colab_type":"code","outputId":"bd829448-430b-40db-9727-90d366561328","executionInfo":{"status":"ok","timestamp":1571633158400,"user_tz":360,"elapsed":15068,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# orginal data\n","data_df = pd.DataFrame(Data)\n","data_df.head(5)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.091501</td>\n","      <td>0.271886</td>\n","      <td>0.704281</td>\n","      <td>0.912466</td>\n","      <td>0.849801</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.348159</td>\n","      <td>0.319929</td>\n","      <td>0.495422</td>\n","      <td>0.816220</td>\n","      <td>0.595497</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.822380</td>\n","      <td>0.736477</td>\n","      <td>0.609998</td>\n","      <td>0.202815</td>\n","      <td>0.155894</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.698584</td>\n","      <td>0.392705</td>\n","      <td>0.400891</td>\n","      <td>0.393834</td>\n","      <td>0.253510</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.418414</td>\n","      <td>0.343772</td>\n","      <td>0.707993</td>\n","      <td>0.775067</td>\n","      <td>0.511391</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1         2         3         4\n","0  0.091501  0.271886  0.704281  0.912466  0.849801\n","1  0.348159  0.319929  0.495422  0.816220  0.595497\n","2  0.822380  0.736477  0.609998  0.202815  0.155894\n","3  0.698584  0.392705  0.400891  0.393834  0.253510\n","4  0.418414  0.343772  0.707993  0.775067  0.511391"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"RuROy02lA6nW","colab_type":"code","outputId":"77d3ef37-fb3b-4a77-e588-c4fd67c89dc5","executionInfo":{"status":"ok","timestamp":1571633158402,"user_tz":360,"elapsed":15052,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# The missing data matrix uses 1 for valid values and 0 for missing NaN values.\n","missing_df = pd.DataFrame(Missing)\n","missing_df.head(5)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     0    1    2    3    4\n","0  1.0  1.0  1.0  0.0  1.0\n","1  1.0  1.0  1.0  1.0  1.0\n","2  1.0  1.0  1.0  1.0  1.0\n","3  0.0  1.0  1.0  0.0  1.0\n","4  1.0  1.0  1.0  0.0  0.0"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"_6hs79EbBPE2","colab_type":"code","outputId":"140a61f9-4106-4f9a-affc-2d39db0342a8","executionInfo":{"status":"ok","timestamp":1571633158403,"user_tz":360,"elapsed":15035,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["result_df = pd.DataFrame(result)\n","result_df.head(5)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.091501</td>\n","      <td>0.271886</td>\n","      <td>0.704281</td>\n","      <td>0.711789</td>\n","      <td>0.849801</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.348159</td>\n","      <td>0.319929</td>\n","      <td>0.495422</td>\n","      <td>0.816220</td>\n","      <td>0.595497</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.822380</td>\n","      <td>0.736477</td>\n","      <td>0.609998</td>\n","      <td>0.202815</td>\n","      <td>0.155894</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.703213</td>\n","      <td>0.392705</td>\n","      <td>0.400891</td>\n","      <td>0.654040</td>\n","      <td>0.253510</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.418414</td>\n","      <td>0.343772</td>\n","      <td>0.707993</td>\n","      <td>0.439732</td>\n","      <td>0.582557</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1         2         3         4\n","0  0.091501  0.271886  0.704281  0.711789  0.849801\n","1  0.348159  0.319929  0.495422  0.816220  0.595497\n","2  0.822380  0.736477  0.609998  0.202815  0.155894\n","3  0.703213  0.392705  0.400891  0.654040  0.253510\n","4  0.418414  0.343772  0.707993  0.439732  0.582557"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"lcVjchYiCxS5","colab_type":"text"},"source":["## Deep Learning Modeling\n","We compare the results creating a model using the real dataset and creating another model using the imputed dataset.\n","\n","We expect to get nearly the same accuracy among models. If the two models give us the same accuracy on a test set, this would be meaning that GAIN method works well generating similar data for filling empty spaces for CCPower Plant dataset."]},{"cell_type":"code","metadata":{"id":"DXv8Ok1pEJ5Q","colab_type":"code","outputId":"92bf1a23-221b-40e8-9444-dd5054e52c8d","executionInfo":{"status":"ok","timestamp":1571633158567,"user_tz":360,"elapsed":15181,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras import regularizers\n","\n","X_imputed = result_df.iloc[:,0:4]      # features\n","Y_imputed = result_df.iloc[:,4]        # predict PE variable \n","\n","X_test = test_set.iloc[:,0:4]\n","Y_test = test_set.iloc[:,4]\n","\n","X_partial = partial_set.iloc[:,0:4]\n","Y_partial = partial_set.iloc[:,4]\n","\n","X_full = full_set.iloc[:,0:4]      # features\n","Y_full = full_set.iloc[:,4]        # predict PE variable \n","\n","# define base model\n","def baseline_model():\n","\t\n","  # define the keras model\n","  model = Sequential()\n","  model.add(Dense(128, input_dim=4, kernel_initializer='normal', activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n","  model.add(Dropout(0.4))\n","  model.add(Dense(64, activation='relu',kernel_initializer='normal',kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n","  model.add(Dropout(0.4))\n","  model.add(Dense(1, kernel_initializer='normal'))\n","  \n","  # compile the keras model\n","  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])\n","  return model"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"msqbjoh4X76_","colab_type":"text"},"source":["## Model for Imputed CCPower Plant Dataset"]},{"cell_type":"code","metadata":{"id":"PMLk38fWTq9c","colab_type":"code","outputId":"dc7cc5f7-287f-48e2-9ebe-5d319ca0eaed","executionInfo":{"status":"ok","timestamp":1571633176029,"user_tz":360,"elapsed":32625,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["# create model\n","model_imputed = baseline_model()\n","# train model\n","model_imputed.fit(X_imputed, Y_imputed, epochs=100, verbose=0, validation_split=0.2)\n","# evaluate model\n","score = model_imputed.evaluate(X_test, Y_test, verbose=0, batch_size=32)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vlY4NlD9ok-Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"c9ec992e-dc48-4253-fabf-c221ba850524","executionInfo":{"status":"ok","timestamp":1571633176030,"user_tz":360,"elapsed":32617,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}}},"source":["print(model_imputed.metrics_names)\n","print(score)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["['loss', 'mean_squared_error', 'mean_absolute_error']\n","[0.0616254753193329, 0.051113099956193495, 0.19581719246197704]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FuopFy1dZdB8","colab_type":"text"},"source":["## Model for Full Original CCPower Plant Dataset"]},{"cell_type":"code","metadata":{"id":"rabOhUnVZrjk","colab_type":"code","outputId":"65a56e91-4849-4ceb-a255-6a9a0bf127eb","executionInfo":{"status":"ok","timestamp":1571633193972,"user_tz":360,"elapsed":50541,"user":{"displayName":"Victor Sergio Peñaloza Martinez","photoUrl":"","userId":"00896402835499373336"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# create model\n","model_full = baseline_model()\n","# train model\n","model_full.fit(X_full, Y_full, epochs=100, verbose=0, validation_split=0.2)\n","# evaluate model\n","score = model_full.evaluate(X_test, Y_test, verbose=0, batch_size=32)\n","\n","print(model_full.metrics_names)\n","print(score)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["['loss', 'mean_squared_error', 'mean_absolute_error']\n","[0.06180433492895752, 0.0511047463477854, 0.19602099624166522]\n"],"name":"stdout"}]}]}